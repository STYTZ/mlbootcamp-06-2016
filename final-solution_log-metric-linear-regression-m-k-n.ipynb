{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>k</th>\n",
       "      <th>n</th>\n",
       "      <th>cacheL1IsShared</th>\n",
       "      <th>cacheL1Size</th>\n",
       "      <th>cacheL2IsShared</th>\n",
       "      <th>cacheL2Size</th>\n",
       "      <th>cacheL3IsShared</th>\n",
       "      <th>cacheL3Size</th>\n",
       "      <th>cacheL1Threads</th>\n",
       "      <th>...</th>\n",
       "      <th>SeqCopy_16MB_by256</th>\n",
       "      <th>SeqCopy_20MB_by256</th>\n",
       "      <th>SeqCopy_21MB_by256</th>\n",
       "      <th>SeqCopy_32MB_by256</th>\n",
       "      <th>SeqCopy_48MB_by256</th>\n",
       "      <th>SeqCopy_64MB_by256</th>\n",
       "      <th>SeqCopy_72MB_by256</th>\n",
       "      <th>SeqCopy_96MB_by256</th>\n",
       "      <th>SeqCopy_128MB_by256</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2500</td>\n",
       "      <td>3500</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5871.6</td>\n",
       "      <td>5454.5</td>\n",
       "      <td>5201.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5724.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>6165.1</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.016325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>4000</td>\n",
       "      <td>4500</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5871.6</td>\n",
       "      <td>5454.5</td>\n",
       "      <td>5201.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5724.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>6165.1</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.108012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>4000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5871.6</td>\n",
       "      <td>5454.5</td>\n",
       "      <td>5201.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5724.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>6165.1</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.388898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2500</td>\n",
       "      <td>4500</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5871.6</td>\n",
       "      <td>5454.5</td>\n",
       "      <td>5201.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5724.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>6165.1</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.368330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2500</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5871.6</td>\n",
       "      <td>5454.5</td>\n",
       "      <td>5201.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5724.8</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>5236.4</td>\n",
       "      <td>6165.1</td>\n",
       "      <td>5120.0</td>\n",
       "      <td>1.496602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 952 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      m     k     n  cacheL1IsShared  cacheL1Size  cacheL2IsShared  \\\n",
       "0  2500  3500  5000                0           32                0   \n",
       "1  2500  4000  4500                0           32                0   \n",
       "2  2500  4000  5000                0           32                0   \n",
       "3  2500  4500  5000                0           32                0   \n",
       "4  2500  5000  5000                0           32                0   \n",
       "\n",
       "   cacheL2Size  cacheL3IsShared  cacheL3Size  cacheL1Threads    ...     \\\n",
       "0          256                1        10240               2    ...      \n",
       "1          256                1        10240               2    ...      \n",
       "2          256                1        10240               2    ...      \n",
       "3          256                1        10240               2    ...      \n",
       "4          256                1        10240               2    ...      \n",
       "\n",
       "   SeqCopy_16MB_by256  SeqCopy_20MB_by256  SeqCopy_21MB_by256  \\\n",
       "0              5871.6              5454.5              5201.8   \n",
       "1              5871.6              5454.5              5201.8   \n",
       "2              5871.6              5454.5              5201.8   \n",
       "3              5871.6              5454.5              5201.8   \n",
       "4              5871.6              5454.5              5201.8   \n",
       "\n",
       "  SeqCopy_32MB_by256  SeqCopy_48MB_by256  SeqCopy_64MB_by256  \\\n",
       "0             5236.4              5724.8              5236.4   \n",
       "1             5236.4              5724.8              5236.4   \n",
       "2             5236.4              5724.8              5236.4   \n",
       "3             5236.4              5724.8              5236.4   \n",
       "4             5236.4              5724.8              5236.4   \n",
       "\n",
       "  SeqCopy_72MB_by256 SeqCopy_96MB_by256  SeqCopy_128MB_by256      time  \n",
       "0             5236.4             6165.1               5120.0  1.016325  \n",
       "1             5236.4             6165.1               5120.0  1.108012  \n",
       "2             5236.4             6165.1               5120.0  1.388898  \n",
       "3             5236.4             6165.1               5120.0  1.368330  \n",
       "4             5236.4             6165.1               5120.0  1.496602  \n",
       "\n",
       "[5 rows x 952 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('x_train.csv')\n",
    "x_test = pd.read_csv('x_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "\n",
    "data = pd.concat( [x_train, y_train], axis=1 ).drop([2583, 2584, 2586, 2587, 2622]) # drop few outliers\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm outline\n",
    "\n",
    "- Group data by system parameters. There are 92 groups, which are the same for train and test set.\n",
    "- Fit a Linear Regression (see details below) for each group using matrix size as features, so there are 92 regressors.\n",
    "- To make a prediction, select a group by system parameters and use corresponding regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = x_train.columns[:3].tolist() # 'm', 'k' and 'n' are features used to fit the regression\n",
    "system_params = x_train.columns[3:].tolist() # other columns define system parameters\n",
    "\n",
    "data_grouped = data.groupby(system_params)\n",
    "systems = pd.DataFrame([n for n, g in data_grouped], columns=system_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression details\n",
    "\n",
    "Consider a design matrix $\\pmb X$ consisting of $N$ training examples $x^{(i)} = \n",
    "\\begin{pmatrix}\n",
    "m^{(i)} & k^{(i)} & n^{(i)}\n",
    "\\end{pmatrix}$.\n",
    "\n",
    "Assume the following model:\n",
    "\n",
    "$$\\hat y_\\theta = \\theta_0 \\, m^{\\theta_1} k^{\\theta_2} n^{\\theta_3}$$\n",
    "\n",
    "If we take a logarithm, we can rewrite this as \n",
    "\n",
    "$$\\log \\hat y_\\theta = \\log \\theta_0 + \\theta_1 \\log m + \\theta_2 \\log k + \\theta_3 \\log n = \\log \\pmb X \\cdot \\pmb\\theta + intercept,$$\n",
    "\n",
    "so we have a linear regression between $\\log \\hat y_\\theta$ and $\\log \\pmb X$ with respect to parameters vector $\\pmb\\theta$ and intercept term.\n",
    "\n",
    "Instead of ordinary least squares, let's take a MRE as objective function:\n",
    "\n",
    "$$\n",
    "J(\\theta) = \n",
    "\\frac1N \\sum\\limits_{i=1}^N \\left| \\frac{ \\hat y_\\theta^{(i)} - y^{(i)} }{y^{(i)}} \\right| = \n",
    "\\frac1N \\sum\\limits_{i=1}^N \\left| \\frac{\\hat y_\\theta^{(i)}}{y^{(i)}} - 1 \\right| = \n",
    "\\frac1N \\sum\\limits_{i=1}^N \\left| e ^ {\\displaystyle \\log \\hat y_\\theta^{(i)} - \\log y^{(i)}} - 1 \\right| =\n",
    "\\frac1N \\sum\\limits_{i=1}^N \\left| e ^ {\\displaystyle \\log \\pmb X^{(i)} \\cdot \\pmb\\theta + intercept - \\log y^{(i)}} - 1 \\right| \\to \\min\\limits_\\theta\n",
    "$$\n",
    "\n",
    "This function is non-convex and hard to minimize, but good results can be obtained using Nelder-Mead method with initial guess $\\pmb\\theta_{init} = \\pmb 1$, $intercept_{init} = \\frac1N \\sum\\limits_{i=1}^N \\left( \\log y^{(i)} - \\log \\pmb X^{(i)} \\cdot \\pmb\\theta \\right)$, which comes from OLS-solution for $\\hat y_\\theta = \\theta \\, m k n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MRELogLinearRegression:\n",
    "    def _errFunc(self, C, X, y):\n",
    "        return np.mean( np.abs(np.exp( np.log(X).dot(C[:-1]) + C[-1] - np.log(y) ) - 1) )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Cinit = np.ones((X.shape[1] + 1,))\n",
    "        Cinit[-1] = np.mean( np.log(y) - np.log(X).dot(Cinit[:-1]) )\n",
    "        self.C = minimize(self._errFunc,\n",
    "                          Cinit,\n",
    "                          (X, y),\n",
    "                          method='Nelder-Mead').x\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.exp( np.log(X).dot(self.C[:-1]) + self.C[-1] )\n",
    "    \n",
    "    def MREscore(self, X, y):\n",
    "        return np.mean( np.abs( self.predict(X) - y ) / y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90 65 85  0 89 72 71  6 77  2 67 87  4 83 79 68 70 91 30 48  1 69 75 43 78\n",
      " 57 36 44 66 53  5  3 16 23 54 74 13 45 61 11 76  7 49 52 50 31 28 60 82 10\n",
      " 14 17 55 38 18 21 25 73 62  9 58 34 88 32  8 46 51 22 15 40 35 12 56 33 63\n",
      " 20 37 29 64 81 24 39 27 86 41 19 42 80 47 26 84 59]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKnDTAKS1GEmAUnqsP8Hlqvd44YOSmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb858898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regressors = {}\n",
    "errors = []\n",
    "for n, g in data_grouped: \n",
    "    rgr = MRELogLinearRegression()\n",
    "    rgr.fit(g[features].values, g.time.values)\n",
    "    regressors[n] = rgr\n",
    "    errors.append( rgr.MREscore(g[features].values, g.time.values) )\n",
    "systems['error'] = errors\n",
    "print(np.argsort(errors))\n",
    "plt.bar(range(len(errors)), np.sort(errors))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049787215146016243"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = x_train.apply(lambda x: regressors[tuple(x[system_params])].predict(x[features].astype('float64').values), axis=1)\n",
    "np.mean(np.abs(y_train_pred - y_train.time) / y_train.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = x_test.apply(lambda x: regressors[tuple(x[system_params])].predict(x[features].astype('float64').values), axis=1)\n",
    "y_test_pred.to_csv('log-metric-linear-regression-m-k-n', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
